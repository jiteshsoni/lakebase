# Lakebase - Async Database Benchmarking & Connection Management

A comprehensive toolkit for benchmarking and managing async database connections with Databricks Lakebase, featuring secure credential management and high-performance connection pooling.

## üöÄ Features

- **Async Database Connections** - High-performance async connections with SQLAlchemy
- **Secure Credential Management** - Environment variables instead of plain JSON files
- **Connection Pooling** - Production-grade connection pooling with health monitoring
- **Benchmarking Tools** - Comprehensive performance testing with 100M+ row datasets
- **FastAPI Integration** - Ready-to-use FastAPI database modules
- **OAuth Token Management** - Automatic background token refresh for Lakebase

## üìÅ Project Structure

```
lakebase/
‚îú‚îÄ‚îÄ README.md                           # This file
‚îú‚îÄ‚îÄ requirements.txt                    # Dependencies
‚îú‚îÄ‚îÄ .gitignore                         # Git ignore rules
‚îú‚îÄ‚îÄ .env                               # Secure credentials (gitignored)
‚îú‚îÄ‚îÄ lakebase_1m_benchmark.py          # Benchmark compatibility wrapper
‚îú‚îÄ‚îÄ async_database_wrapper.py          # Async database compatibility wrapper
‚îú‚îÄ‚îÄ FASTAPI_INTEGRATION_GUIDE.md       # FastAPI integration guide
‚îú‚îÄ‚îÄ NIKHIL_WEBSITE_GUIDE.md            # Website integration guide
‚îÇ
‚îú‚îÄ‚îÄ src/                               # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ core/                          # Core functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py                    # Authentication management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pool.py                    # Connection pooling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.py                   # Utility functions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ secure_credentials.py      # Secure credential management
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/                    # Monitoring and health
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ performance.py             # Performance monitoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py                  # Health monitoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ error.py                   # Error handling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fastapi_monitoring.py      # FastAPI monitoring
‚îÇ   ‚îî‚îÄ‚îÄ database/                      # Database connections
‚îÇ       ‚îî‚îÄ‚îÄ async_database.py          # Async database module
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Executable scripts
‚îÇ   ‚îú‚îÄ‚îÄ benchmark.py                   # Main benchmark script
‚îÇ   ‚îú‚îÄ‚îÄ setup_secure_env.py            # Secure environment setup
‚îÇ   ‚îî‚îÄ‚îÄ test_lakebase_only.py          # Lakebase-only testing
‚îÇ
‚îú‚îÄ‚îÄ tests/                             # Test files
‚îÇ   ‚îú‚îÄ‚îÄ test_lakebase_only.py          # Lakebase testing
‚îÇ   ‚îî‚îÄ‚îÄ test_mysql_vs_lakebase.py      # MySQL vs Lakebase comparison
‚îÇ
‚îú‚îÄ‚îÄ examples/                          # Example implementations
‚îÇ   ‚îú‚îÄ‚îÄ demo_results.py                # Demo results
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_benchmark_example.py  # Enhanced benchmarking
‚îÇ   ‚îî‚îÄ‚îÄ test_comparison_simple.py      # Simple comparison test
‚îÇ
‚îî‚îÄ‚îÄ config/                            # Configuration examples
    ‚îú‚îÄ‚îÄ production_config_example.json # Production config template
    ‚îî‚îÄ‚îÄ rate_limiting_config_example.json # Rate limiting config
```

## üîê Secure Credential Management

This project uses **environment variables** instead of plain JSON files for secure credential management.

### Setup Secure Environment

1. **Create environment template:**
   ```bash
   python scripts/setup_secure_env.py template
   ```

2. **Configure your credentials:**
   ```bash
   cp .env.template .env
   # Edit .env with your actual credentials
   ```

3. **Validate configuration:**
   ```bash
   python scripts/setup_secure_env.py validate
   ```

### Required Environment Variables

```bash
# Databricks Configuration
DATABRICKS_HOST=https://your-workspace.cloud.databricks.com
LAKEFUSION_DATABRICKS_DAPI=dapi_your_personal_access_token_here
DATABRICKS_WORKSPACE_ID=your_workspace_id_here
DATABRICKS_USERNAME=your.email@company.com

# Lakebase Database Configuration
DATABRICKS_DATABASE_INSTANCE=your-benchmark-instance
DATABRICKS_DATABASE_HOST=instance-your-id.database.cloud.databricks.com
DATABRICKS_DATABASE_PORT=5432
DATABRICKS_DATABASE_NAME=databricks_postgres

# Connection Pool Configuration
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=30
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3000

# Service Configuration
SERVICE_NAME=LakeFusionDBService
DB_TYPE=lakebase
```

## üöÄ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Set Up Secure Credentials

```bash
python scripts/setup_secure_env.py template
cp .env.template .env
# Edit .env with your credentials
python scripts/setup_secure_env.py validate
```

### 3. Run Benchmark

```bash
python lakebase_1m_benchmark.py
```

### 4. Use in FastAPI

```python
from fastapi import FastAPI, Depends
from async_database_wrapper import get_db, lifespan

app = FastAPI(lifespan=lifespan)

@app.get("/")
async def root(db = Depends(get_db)):
    return {"message": "Hello World"}
```



## üìä Benchmarking

The benchmark script tests Lakebase performance with:

- **100M+ row datasets** for realistic testing
- **Multi-threaded concurrent queries** (20-300 threads)
- **Connection pooling** with OAuth rate limiting mitigation
- **Comprehensive metrics** (throughput, latency, error rates)


### Benchmark Configuration

```python
# Default benchmark settings
thread_counts = [20, 40, 80, 100]  # Concurrent connections
test_duration = 30                  # Seconds per test
table_rows = 100000000             # 100M rows
batch_size = 10000                 # Batch size for operations
```

### Running Benchmarks

```bash
# Run full benchmark suite
python lakebase_1m_benchmark.py

# Run specific test
python tests/test_mysql_vs_lakebase.py

# Run Lakebase-only tests
python tests/test_lakebase_only.py
```



## üîß Database Connection Features

### Async Database Module

- **Async SQLAlchemy** connections with `asyncpg`
- **Background token refresh** every 50 minutes
- **Connection pooling** with health monitoring
- **Error handling** and automatic recovery
- **FastAPI integration** with lifespan management

### Connection Pool Configuration

```python
pool_size = 20                    # Base pool size
max_overflow = 30                 # Maximum overflow connections
pool_timeout = 30                 # Pool checkout timeout
pool_recycle = 3000              # Pool recycle interval
```

## üß™ Testing

### Run All Tests

```bash
# Run Lakebase-only tests
python tests/test_lakebase_only.py

# Run MySQL vs Lakebase comparison
python tests/test_mysql_vs_lakebase.py
```

### Test Categories

- ‚úÖ **Lakebase Connection** - Database connectivity tests
- ‚úÖ **MySQL vs Lakebase** - Performance comparison tests
- ‚úÖ **Configuration** - Secure credential validation
- ‚úÖ **Benchmark** - Performance testing with various thread counts
- ‚úÖ **Async Database** - Connection management and pooling

## üìà Performance Features

### Connection Pooling

- **Pre-warmed connections** for faster startup
- **Health monitoring** with automatic cleanup
- **OAuth rate limiting** mitigation
- **Background maintenance** tasks

### Monitoring

- **Performance metrics** collection
- **Health checks** for database connections
- **Error tracking** and categorization
- **Real-time monitoring** capabilities

## üîí Security

### Credential Management

- ‚úÖ **Environment variables** instead of JSON files
- ‚úÖ **No hardcoded secrets** in code
- ‚úÖ **Secure token storage** and rotation
- ‚úÖ **Non-sensitive logging** only

### Best Practices

- Never commit `.env` files to version control
- Use secure credential storage in production
- Rotate tokens regularly
- Monitor access logs

## üìã Requirements

```
pydantic==2.11.5
pydantic-settings==2.9.1
python-dotenv==1.1.0
databricks-sdk==0.56.0
psycopg2-binary==2.9.9
fastapi==0.115.12
uvicorn==0.34.3
asyncpg==0.30.0
sqlalchemy==2.0.41
sqlmodel>=0.0.24
aiomysql==0.2.0
PyJWT==2.8.0
```

## üéØ Usage Examples

### Basic Database Connection

```python
from async_database_wrapper import get_db, init_engine

# Initialize database
init_engine()

# Use in FastAPI
@app.get("/users")
async def get_users(db = Depends(get_db)):
    result = await db.execute("SELECT * FROM users LIMIT 10")
    return result.fetchall()
```

### Custom Benchmark

```python
# Run the main benchmark script
python scripts/benchmark.py

# Or use the wrapper
python lakebase_1m_benchmark.py

# Test examples
python examples/enhanced_benchmark_example.py
```

### Secure Environment Setup

```python
from src.core.secure_credentials import setup_secure_environment, validate_secure_credentials

# Set up secure environment
setup_secure_environment()

# Validate credentials
if validate_secure_credentials():
    print("‚úÖ Credentials are valid")
```

## üö® Troubleshooting

### Common Issues

1. **Missing Environment Variables**
   ```bash
   python scripts/setup_secure_env.py validate
   ```

2. **Import Errors**
   ```bash
   pip install -r requirements.txt
   ```

3. **Database Connection Issues**
   - Check your Databricks credentials
   - Verify network connectivity
   - Check token expiration

### Debug Mode

```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
python lakebase_1m_benchmark.py
```

## ‚ö†Ô∏è Important Notes

- **Use at your own risk** - This toolkit is provided as-is without warranties
- **Benchmark for your own use-case** - Performance results may vary based on your specific environment, data, and configuration

## üìÑ License

This project is for internal use at Databricks.

## ü§ù Contributing

1. Follow secure credential management practices
2. Add tests for new features
3. Update documentation for changes
4. Use async patterns for database operations

---

**Note**: This project uses secure credential management with environment variables. Never commit `.env` files or hardcoded secrets to version control.
